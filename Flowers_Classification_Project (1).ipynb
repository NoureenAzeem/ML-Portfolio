{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# \ud83c\udf38 Flowers Classification with Pre-trained CNNs (Colab Project)\n", "---\n", "This notebook trains image classifiers using **VGG16** and **MobileNetV2** on the Flowers Recognition dataset.\n", "It includes dataset download, preprocessing, training, evaluation, and saving models for deployment with Streamlit."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Step 1: Mount Google Drive (optional, for saving models)\n", "from google.colab import drive\n", "drive.mount('/content/drive')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Step 2: Install & Set up Kaggle API\n", "!pip install -q kaggle\n", "\n", "# Upload kaggle.json (download from Kaggle > Account > Create API Token)\n", "from google.colab import files\n", "files.upload()  # Upload kaggle.json file here\n", "\n", "!mkdir -p ~/.kaggle\n", "!cp kaggle.json ~/.kaggle/\n", "!chmod 600 ~/.kaggle/kaggle.json"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Step 3: Download Flowers Recognition dataset\n", "!kaggle datasets download -d alxmamaev/flowers-recognition\n", "\n", "import zipfile\n", "with zipfile.ZipFile(\"flowers-recognition.zip\", 'r') as zip_ref:\n", "    zip_ref.extractall(\"flowers_dataset\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Step 4: Prepare Data Generators\n", "import tensorflow as tf\n", "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n", "\n", "train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n", "\n", "train_generator = train_datagen.flow_from_directory(\n", "    'flowers_dataset/flowers',\n", "    target_size=(150, 150),\n", "    batch_size=32,\n", "    subset='training')\n", "\n", "val_generator = train_datagen.flow_from_directory(\n", "    'flowers_dataset/flowers',\n", "    target_size=(150, 150),\n", "    batch_size=32,\n", "    subset='validation')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Step 5: Build Model using VGG16\n", "from tensorflow.keras.applications import VGG16\n", "from tensorflow.keras.models import Sequential\n", "from tensorflow.keras.layers import Dense, Flatten, Dropout\n", "\n", "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(150,150,3))\n", "base_model.trainable = False\n", "\n", "model_vgg = Sequential([\n", "    base_model,\n", "    Flatten(),\n", "    Dense(256, activation='relu'),\n", "    Dropout(0.5),\n", "    Dense(5, activation='softmax')\n", "])\n", "\n", "model_vgg.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n", "history_vgg = model_vgg.fit(train_generator, validation_data=val_generator, epochs=5)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Step 6: Build Model using MobileNetV2\n", "from tensorflow.keras.applications import MobileNetV2\n", "\n", "base_model2 = MobileNetV2(weights='imagenet', include_top=False, input_shape=(150,150,3))\n", "base_model2.trainable = False\n", "\n", "model_mobilenet = Sequential([\n", "    base_model2,\n", "    Flatten(),\n", "    Dense(256, activation='relu'),\n", "    Dropout(0.5),\n", "    Dense(5, activation='softmax')\n", "])\n", "\n", "model_mobilenet.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n", "history_mobilenet = model_mobilenet.fit(train_generator, validation_data=val_generator, epochs=5)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Step 7: Evaluate Models\n", "import matplotlib.pyplot as plt\n", "\n", "plt.plot(history_vgg.history['accuracy'], label='VGG16 Train')\n", "plt.plot(history_vgg.history['val_accuracy'], label='VGG16 Val')\n", "plt.plot(history_mobilenet.history['accuracy'], label='MobileNet Train')\n", "plt.plot(history_mobilenet.history['val_accuracy'], label='MobileNet Val')\n", "plt.legend()\n", "plt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Step 8: Save Best Model\n", "model_vgg.save('/content/drive/MyDrive/flowers_vgg16.h5')\n", "model_mobilenet.save('/content/drive/MyDrive/flowers_mobilenet.h5')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["---\n", "## \ud83d\ude80 Streamlit Deployment (app.py)\n", "```python\n", "import streamlit as st\n", "import tensorflow as tf\n", "from tensorflow.keras.preprocessing import image\n", "import numpy as np\n", "\n", "model = tf.keras.models.load_model('flowers_vgg16.h5')\n", "class_names = ['daisy','dandelion','rose','sunflower','tulip']\n", "\n", "st.title('\ud83c\udf38 Flower Classifier')\n", "file = st.file_uploader('Upload an image', type=['jpg','png','jpeg'])\n", "if file:\n", "    img = image.load_img(file, target_size=(150,150))\n", "    img_array = image.img_to_array(img)/255.0\n", "    img_array = np.expand_dims(img_array, axis=0)\n", "    pred = np.argmax(model.predict(img_array))\n", "    st.write(f'Prediction: {class_names[pred]}')\n", "```\n", "---"]}], "metadata": {"colab": {"name": "Flowers_Classification_Project.ipynb"}, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.9"}}, "nbformat": 4, "nbformat_minor": 0}